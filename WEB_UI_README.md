# 微博搜索Web系统使用说明

## 功能特点

- ✅ 美观的Web界面，支持响应式设计
- ✅ 关键词搜索功能
- ✅ Cookie配置管理
- ✅ 自定义时间范围搜索
- ✅ 实时显示搜索结果
- ✅ 支持图片预览
- ✅ 显示推文详细信息（转发、评论、点赞等）

## 安装步骤

### 1. 安装依赖

```bash
pip install -r requirements.txt
```

### 2. 配置Cookie

有两种方式配置Cookie：

**方式一：通过Web界面配置**
1. 启动Web系统后，点击"Cookie配置"按钮
2. 从浏览器开发者工具中复制Cookie值
3. 粘贴到输入框并保存

**方式二：直接编辑文件**
1. 打开 `weibospider/cookie.txt` 文件
2. 将从浏览器复制的Cookie粘贴进去

**如何获取Cookie：**
1. 打开浏览器，访问 https://weibo.com 并登录
2. 按 F12 打开开发者工具
3. 切换到 Network（网络）标签
4. 刷新页面，找到任意一个请求
5. 在请求头中找到 Cookie，复制完整内容

## 启动系统

### Windows

```bash
python start_web.py
```

### Linux/Mac

```bash
python3 start_web.py
```

启动后，在浏览器中访问：**http://localhost:5000**

## 使用说明

### 1. 搜索微博

1. 在"搜索关键词"输入框中输入要搜索的关键词
2. 选择开始时间和结束时间
3. （可选）勾选"按小时切分"选项（适用于热门关键词）
4. 点击"开始搜索"按钮

### 2. 查看结果

- 搜索结果会实时显示在页面上
- 每条推文显示：
  - 用户头像和昵称
  - 推文内容
  - 发布时间
  - IP属地
  - 转发数、评论数、点赞数
  - 图片（可点击预览）
  - 原文链接

### 3. Cookie管理

- 点击"Cookie配置"按钮展开配置面板
- 输入Cookie值并保存
- Cookie会保存到 `weibospider/cookie.txt` 文件中

## 注意事项

1. **Cookie有效期**：Cookie可能会过期，如果搜索失败，请重新获取并更新Cookie
2. **请求频率**：系统已内置延迟机制，避免请求过快被封
3. **时间范围**：建议时间范围不要太大，避免数据量过大导致搜索时间过长
4. **按小时切分**：对于非热门关键词，不建议勾选此选项，会显著增加搜索时间

## 技术架构

- **后端框架**：Flask
- **前端框架**：Bootstrap 5
- **爬虫引擎**：基于 requests 库实现
- **数据解析**：复用原有 Scrapy 爬虫的解析逻辑

## 文件结构

```
WeiboSpider/
├── app.py                 # Flask应用主文件
├── spider_service.py      # 爬虫服务模块
├── start_web.py          # 启动脚本
├── templates/
│   └── index.html        # Web界面模板
├── weibospider/          # 原有爬虫模块
└── output/               # 输出目录（可选，Web界面不直接使用）
```

## 常见问题

### Q: 搜索没有结果？
A: 检查Cookie是否有效，时间范围是否合理，关键词是否正确

### Q: 搜索很慢？
A: 这是正常的，系统需要逐页爬取数据。可以缩小时间范围或取消"按小时切分"选项

### Q: 如何停止搜索？
A: 刷新页面即可停止当前搜索任务

### Q: Cookie在哪里获取？
A: 浏览器开发者工具 -> Network标签 -> 任意请求 -> Request Headers -> Cookie

## 更新日志

- 2024.12: 创建Web UI系统
  - 添加Flask Web界面
  - 实现关键词搜索功能
  - 添加Cookie配置管理
  - 实现实时结果展示

